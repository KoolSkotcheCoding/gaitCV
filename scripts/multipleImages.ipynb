{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "pathToOpenPose='/home/kschuma/Projects/learnopencv/OpenPose/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths for the 2 files\n",
    "protoFile = pathToOpenPose+\"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = pathToOpenPose+\"pose/mpi/pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Read the network into Memory\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input image dimensions\n",
    "inWidth = 500\n",
    "inHeight = 500\n",
    "#read in images\n",
    "imagePath='/home/kschuma/Projects/gaitCV/images/'\n",
    "images=[]\n",
    "for i in range(1,5):\n",
    "    images.append(cv2.imread(imagePath+'pinkPants'+str(i)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(404, 0),\n",
       "  (365, 79),\n",
       "  (388, 119),\n",
       "  (357, 206),\n",
       "  (396, 111),\n",
       "  (309, 95),\n",
       "  (246, 126),\n",
       "  (277, 142),\n",
       "  (341, 238),\n",
       "  (142, 365),\n",
       "  (71, 420),\n",
       "  (293, 230),\n",
       "  (142, 373),\n",
       "  (71, 420),\n",
       "  (325, 166)],\n",
       " 1: [(349, 39),\n",
       "  (333, 87),\n",
       "  (349, 111),\n",
       "  (357, 134),\n",
       "  (365, 111),\n",
       "  (309, 95),\n",
       "  (238, 126),\n",
       "  (277, 190),\n",
       "  (317, 230),\n",
       "  (190, 341),\n",
       "  (206, 333),\n",
       "  (285, 222),\n",
       "  (222, 325),\n",
       "  (206, 341),\n",
       "  (309, 166)],\n",
       " 2: [(349, 0),\n",
       "  (325, 71),\n",
       "  (349, 103),\n",
       "  (373, 142),\n",
       "  (380, 142),\n",
       "  (277, 95),\n",
       "  (222, 126),\n",
       "  (253, 158),\n",
       "  (309, 238),\n",
       "  (214, 325),\n",
       "  (198, 349),\n",
       "  (269, 222),\n",
       "  (388, 325),\n",
       "  (388, 420),\n",
       "  (301, 158)],\n",
       " 3: [(365, 0),\n",
       "  (325, 71),\n",
       "  (349, 87),\n",
       "  (230, 134),\n",
       "  (317, 190),\n",
       "  (285, 87),\n",
       "  (230, 134),\n",
       "  (269, 190),\n",
       "  (269, 246),\n",
       "  (214, 341),\n",
       "  (158, 309),\n",
       "  (325, 261),\n",
       "  (380, 325),\n",
       "  (380, 412),\n",
       "  (293, 166)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoPoints = {}\n",
    "frame=[]\n",
    "for frameNumber,image in enumerate(images):\n",
    "    frame.append(cv2.resize(image, (inWidth, inHeight)))\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame[frameNumber], 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    net.setInput(inpBlob)\n",
    "    out = net.forward() \n",
    "    threshold = .1\n",
    "    H = out.shape[2]\n",
    "    W = out.shape[3]\n",
    "    points=[]\n",
    "    for i in range(15):\n",
    "        probMap = out[0, i, :, :]\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "        x = (frame[frameNumber].shape[1] * point[0]) / W\n",
    "        y = (frame[frameNumber].shape[0] * point[1]) / H\n",
    "        #if prob > threshold : \n",
    "        if True:\n",
    "            cv2.circle(frame[frameNumber], (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame[frameNumber], \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "        else:\n",
    "            points.append(None)\n",
    "    #print points\n",
    "    videoPoints[frameNumber]=points\n",
    "videoPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store the detected keypoints\n",
    "\n",
    "for i,pic in enumerate(frame): \n",
    "    cv2.imshow(\"Output-Keypoints\",pic)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
